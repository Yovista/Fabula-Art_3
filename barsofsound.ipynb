{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "from math import ceil, floor\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1 = list(range(100))\n",
    "lst2 =list(np.random.randint(low = 1,high=3000,size=100))\n",
    "df = pd.DataFrame(\n",
    "    {'No': lst1,\n",
    "     'Bw': lst2,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('histogram.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram= df.to_dict('r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miditime.miditime import MIDITime\n",
    "mymidi = MIDITime(300, 'histilist.mid', 70, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_timed_b = [{'beat': mymidi.beat(d['No']), 'freq': d['Bw']} for d in histogram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_timeb = my_data_timed_b[0]['beat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_to_pitch_tunedb(freq):\n",
    "    scale_pctb = mymidi.linear_scale_pct(min([x['Bw'] for x in histogram]), 3000, freq)\n",
    "\n",
    "\n",
    "    c_major = [\"C\", \"C#\", \"Db\", \"D\", \"D#\", \"Eb\", \"E\", \"F\", \"F#\", \"Gb\", \"G\", \"G#\", \"Ab\", \"A\", \"A#\", \"Bb\", \"B\"]\n",
    "\n",
    "\n",
    "    noteb = mymidi.scale_to_note_classic(scale_pctb, c_major)\n",
    "\n",
    "\n",
    "\n",
    "    midi_pitchb = mymidi.note_to_midi_pitch(noteb)\n",
    "\n",
    "    \n",
    "    return midi_pitchb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_listb = []\n",
    "\n",
    "for d in my_data_timed_b:\n",
    "    note_listb.append([\n",
    "        d['beat'] - start_timeb,\n",
    "        mag_to_pitch_tunedb(d['freq']),\n",
    "        100,  # velocity\n",
    "        1  # duration, in beats\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a track with those notes\n",
    "mymidi.add_track(note_listb)\n",
    "# Output the .mid file\n",
    "mymidi.save_midi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.generators import Sine\n",
    "from collections import defaultdict\n",
    "from mido import MidiFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def note_to_freq(note, concert_A=440.0):\n",
    "    \n",
    "    return (2.0 ** ((note - 69) / 12.0)) * concert_A\n",
    "\n",
    "mid = MidiFile(\"histilist.mid\")\n",
    "output = AudioSegment.silent(mid.length * 2000.0)\n",
    "\n",
    "tempo = 150 # bpm\n",
    "output = output.low_pass_filter(1000)\n",
    "\n",
    "def ticks_to_ms(ticks):\n",
    "    tick_ms = (60000.0 / tempo) / mid.ticks_per_beat\n",
    "    return ticks * tick_ms\n",
    "  \n",
    "\n",
    "for track in mid.tracks:\n",
    "  \n",
    "    current_pos = 0.0\n",
    "\n",
    "    current_notes = defaultdict(dict)\n",
    "\n",
    "    for msg in track:\n",
    "        current_pos += ticks_to_ms(msg.time)\n",
    "\n",
    "        if msg.type == 'note_on':\n",
    "            current_notes[msg.channel][msg.note] = (current_pos, msg)\n",
    "\n",
    "        if msg.type == 'note_off':\n",
    "            start_pos, start_msg = current_notes[msg.channel].pop(msg.note)\n",
    "\n",
    "            duration = current_pos - start_pos\n",
    "\n",
    "            signal_generator = Sine(note_to_freq(msg.note))\n",
    "            rendered = signal_generator.to_audio_segment(duration=duration, volume=-20).fade_out(300).fade_in(30)\n",
    "\n",
    "            output = output.overlay(rendered, start_pos)\n",
    "\n",
    "output.export(\"histlist.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pedalboard import *\n",
    "from pedalboard.io import AudioFile\n",
    "\n",
    "with AudioFile('histlist.mp3', 'r') as f:\n",
    "    audio = f.read(f.frames)\n",
    "    samplerate = f.samplerate\n",
    "\n",
    "# Make a pretty interesting sounding guitar pedalboard:\n",
    "board = Pedalboard([\n",
    "    Compressor(),\n",
    "    Reverb(room_size=1),\n",
    "    Delay(delay_seconds=0.24, mix=0.8)\n",
    "])\n",
    "\n",
    "# Pedalboard objects behave like lists, so you can add plugins:\n",
    "board.append(Gain(gain_db=10 ))\n",
    "\n",
    "\n",
    "# Run the audio through this pedalboard!\n",
    "effected = board(audio, samplerate)\n",
    "\n",
    "\n",
    "# Write the audio back as a wav file:\n",
    "with AudioFile('output.mp3', 'w', samplerate, effected.shape[0]) as f:\n",
    "    f.write(effected)\n",
    "\n",
    "song = AudioSegment.from_mp3(\"output.mp3\")\n",
    "song=song.fade_in(2000).fade_out(3000)\n",
    "song.export(\"output.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, librosa.display\n",
    "from mobilechelonian import Turtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name =\"output\"\n",
    "file = name+\".mp3\"\n",
    "title =name+\".ps\"\n",
    "png = name + '.png'\n",
    "frame_count=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, sample_rate = librosa.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_SIZE = 2028\n",
    "HOP_LENGTH = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = librosa.feature.rms(signal, frame_length=FRAME_SIZE, hop_length=HOP_LENGTH)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = []\n",
    "for i in rms:\n",
    "    spec.append(i*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turtle\n",
    "import time\n",
    "from turtle import Screen, Turtle\n",
    "from random import randint\n",
    "import random\n",
    "import PIL.Image\n",
    "from tkinter import *\n",
    "import itertools\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "image_path = os.path.join(current_directory, r'visual')\n",
    "if not os.path.exists(image_path):\n",
    "    os.makedirs(image_path)\n",
    "\n",
    "window = turtle.Screen()\n",
    "window.title(str(name))\n",
    "window.setup(width = 650, height = 650)\n",
    "cv = turtle.getcanvas()\n",
    "turtle.hideturtle()\n",
    "turtle.speed(0)\n",
    "\n",
    "\n",
    "\n",
    "colors = ['white','yellow'\n",
    "         ]\n",
    "angle = [95,105,115,125,135,145,155,165,175]\n",
    "width = [0,2,5]\n",
    "turtle.penup()\n",
    "\n",
    "turtle.penup()\n",
    "turtle.pencolor('white')\n",
    "turtle.width(3)\n",
    "turtle.fillcolor('black')\n",
    "turtle.begin_fill()\n",
    "turtle.goto(-300,-300)\n",
    "turtle.pendown()\n",
    "turtle.goto(300,-300)\n",
    "turtle.goto(300,300)\n",
    "turtle.goto(-300,300)\n",
    "turtle.goto(-300,-300)\n",
    "turtle.end_fill()\n",
    "turtle.penup()\n",
    "\n",
    "\n",
    "for s in spec:\n",
    "    c= random.choice(colors)\n",
    "    w=random.choice(width)\n",
    "    a= random.choice(angle)\n",
    "    turtle.goto(randint(-50,50),-50)\n",
    "    turtle.setheading(90)\n",
    "    turtle.pendown()\n",
    "    turtle.pencolor(c)\n",
    "    turtle.width(w)\n",
    "    turtle.pendown\n",
    "    turtle.forward(i*7000)\n",
    "    turtle.penup()\n",
    "        \n",
    "        \n",
    "cv.postscript(file=title, colormode='color')\n",
    "\n",
    "img = PIL.Image.open(title)\n",
    "img.load(scale=10)  \n",
    "img.save(png,'png')  #final result from sound to image\n",
    "\n",
    "\n",
    "turtle.done()\n",
    "\n",
    "print('is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output.mp4.\n",
      "MoviePy - Writing audio in temp-audio.m4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output.mp4\n"
     ]
    }
   ],
   "source": [
    "#compiling image & sound-\n",
    "videoclip = ImageClip(\"output.png\")\n",
    "audioclip = AudioFileClip(\"output.mp3\")\n",
    "videoclip = videoclip.set_duration(audioclip.duration)\n",
    "videoclip = videoclip.set_audio(AudioFileClip(\"output.mp3\"))\n",
    "videoclip.write_videofile('output.mp4',fps=4,temp_audiofile='temp-audio.m4a', remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
